# Лабораторна робота №1. Організація робочого простору MLOps інженера та автоматизація відстеження експериментів

## Мета роботи
1. Опанувати навички налаштування професійного ізольованого середовища
розробки для Data Science проєктів.
2. Засвоїти принципи структурування ML-проєктів згідно зі стандартами індустрії
(Cookiecutter Data Science).
3. Навчитися використовувати інструменти контролю версій (Git) з урахуванням
специфіки ML-проєктів (ігнорування даних, артефактів).
4. Реалізувати автоматизоване відстеження експериментів (Experiment Tracking) за
допомогою платформи MLflow.
5. Провести первинний аналіз даних (EDA) та побудувати базову модель (Baseline)
для обраного датасету.

## Завдання для виконання
1. Налаштувати локальне середовище розробки: встановити Python, Git, створити
віртуальне середовище.
2. Ініціалізувати Git-репозиторій та налаштувати файл .gitignore.
3. Обрати датасет із запропонованого переліку (див. Додаток А) та завантажити його
у відповідну директорію проєкту.
4. Створити Jupyter Notebook для первинного аналізу даних (EDA).
5. Розробити Python-скрипт для тренування моделі, реалізувавши логіку
завантаження даних, передобробки та навчання.
6. Інтегрувати у скрипт функціонал MLflow для логування гіперпараметрів, метрик
якості та артефактів моделі.
7. Виконати мінімум 5 експериментів з різними налаштуваннями та порівняти їх
результати у MLflow UI.

## Додаткові пояснення
### Структурування проєкту
Створіть базову структуру каталогів, яка відповідає спрощеному стандарту Cookiecutter
Data Science (приклад):
mkdir data
mkdir data/raw # Для сирих даних (read-only)
mkdir notebooks # Для Jupyter ноутбуків
mkdir src # Для скриптів Python
mkdir models # Для збережених моделей

### Завантаження даних
1. Оберіть один датасет зі списку варіантів (див. Додаток А) або використайте
власний датасет.
2. Завантажте файл (наприклад, dataset.csv) у папку data/raw/.

### Первинний аналіз даних (EDA)
1. Запустіть Jupyter Notebook: jupyter notebook.
2. Створіть файл notebooks/01_eda.ipynb
3. Виконайте базовий аналіз:
– Завантаження даних (pd.read_csv).
– Перевірка типів даних та пропусків (df.info(), df.isnull().sum()).
– Візуалізація розподілу цільової змінної (Target Distribution).
– Побудова матриці кореляції.

### Розробка скрипту навчання з MLflow
Необхідно самостійно імплементувати файли для тренування та пов'язані модулі, які
реалізують повний цикл навчання моделі.
Вимоги до скрипту:
1. Завантаження даних: Зчитування CSV/Other types з папки data/raw/.
2. Передобробка: Обробка пропущених значень, кодування категоріальних змінних
(якщо є), розділення на X (ознаки) та y (цільова змінна).
3. Розділення вибірки: Використання train_test_split для створення тренувального та
тестового наборів.
4. Ініціалізація MLflow: Встановлення імені експерименту (mlflow.set_experiment).
5. Логування: У блоці with mlflow.start_run(): необхідно залогувати:
– Гіперпараметри моделі (наприклад, n_estimators, max_depth, learning_rate).
– Метрики якості на тестовій вибірці (accuracy, f1_score, rmse тощо).
– Саму навчену модель (mlflow.sklearn.log_model).
– Графік (наприклад, Confusion Matrix або Feature Importance) як артефакт.

### Розширення функціоналу
Модифікуйте скрипти для відповідності професійним стандартам:
1. CLI Аргументи: Гіперпараметри повинні передаватися як аргументи командного
рядка (використовуючи бібліотеку argparse або click), а не бути "захардкоженими".
2. Feature Importance: Додайте логування графіку важливості ознак, який показує,
які змінні найбільше вплинули на рішення моделі.
3. Розширене логування (Tags):
– Додайте використання mlflow.set_tag() для додавання метаданих (наприклад,
автор запуску, версія датасету, тип моделі).
– Продемонструйте, як в MLflow UI можна фільтрувати запуски,
використовуючи Search query (наприклад, tags.model_type = "RandomForest").

### Перевірка результатів
1. Запустіть розроблені скрипти навчання, наприклад:
python src/train.py
2. Проведіть дослідження впливу гіперпараметрів (Hyperparameter Tuning
Analysis):
– Оберіть один ключовий гіперпараметр (наприклад, max_depth для дерев або
n_neighbors для KNN).
– Виконайте мінімум 5 запусків, послідовно змінюючи значення цього
параметра (від недостатнього до надлишкового).
– Важливо: Логуйте метрики (accuracy, f1) як для тестової, так і для
тренувальної вибірки. Це дозволить побачити момент, коли модель
починає перенавчатися (Overfitting).
3. Запустіть інтерфейс MLflow:
mlflow ui
4. Відкрийте браузер за адресою http://127.0.0.1:5000.
5. Переконайтеся, що:
– Створено експеримент з вашою назвою.
– Відображається список запусків (Runs).
– Використайте функцію "Compare": Виділіть всі ваші запуски та натисніть
"Compare". Побудуйте графік залежності метрики (Y-axis) від
гіперпараметра (X-axis). Проаналізуйте отримані криві.

### Відомості по датасету
Stroke Prediction Dataset (Classification)
– Задача: Передбачення інсульту.
– Особливості: Дуже сильний дисбаланс (1.8% позитивних), медичні дані.
– Джерело: Kaggle Link https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset

### Структура проєкту (приклад)
mlops_lab_1/
├── .gitignore # Файл виключень Git
├── requirements.txt # Список залежностей
├── README.md # Опис проєкту
├── venv/ # Віртуальне середовище (не в Git)
├── data/
│ └── raw/ # Сирі дані (не в Git)
│ └── dataset.csv
├── notebooks/
│ └── 01_eda.ipynb # Ноутбук з аналізом
├── src/
│ └── train.py # Скрипт навчання
├── mlruns/ # Логи MLflow (не в Git)
└── models/ # Збережені моделі (не в Git)